{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e8a81d12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'extract_data' from 'steam_games_scrapper' (D:\\my-folder\\Uni\\bs data science\\5\\DAV\\multimodal-game-success-prediction\\scraped_data_indie\\steam_games_scrapper.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfutures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor, as_completed\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msteam_games_scrapper\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msgc\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msteam_games_scrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_data\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'extract_data' from 'steam_games_scrapper' (D:\\my-folder\\Uni\\bs data science\\5\\DAV\\multimodal-game-success-prediction\\scraped_data_indie\\steam_games_scrapper.py)"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import steam_games_scrapper as sgc\n",
    "from steam_games_scrapper import extract_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b02f56f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T09:48:29.418621Z",
     "iopub.status.busy": "2024-10-27T09:48:29.418165Z",
     "iopub.status.idle": "2024-10-27T10:04:05.008894Z",
     "shell.execute_reply": "2024-10-27T10:04:05.007139Z",
     "shell.execute_reply.started": "2024-10-27T09:48:29.418564Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def save_batch_to_csv(batch_number, df, directory='scraped_data_1'):\n",
    "    \"\"\"Save a DataFrame to a CSV file in a specified directory.\n",
    "\n",
    "    Parameters:\n",
    "        batch_number (int): Batch identifier for the file name.\n",
    "        df (pd.DataFrame): DataFrame containing batch data.\n",
    "        directory (str): Directory path where the CSV file will be saved. Defaults to 'scraped_data_1'.\n",
    "    \"\"\"\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    file_path = os.path.join(directory, f'steam_games_data_batch_{batch_number}.csv')\n",
    "    df.to_csv(file_path, index=False)\n",
    "    logging.info(f\"Batch {batch_number} saved successfully to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0602ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='scraping_log.log', \n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b386a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_number, app_ids, max_workers=8, batch_pause=5):\n",
    "    \"\"\"Process a batch of app IDs, save results to CSV, and pause after each batch.\n",
    "\n",
    "    Parameters:\n",
    "        batch_number (int): Batch number for file naming.\n",
    "        app_ids (list): List of app IDs to process.\n",
    "        max_workers (int): Maximum number of threads for concurrent execution. Defaults to 10.\n",
    "        batch_pause (int): Number of seconds to wait after each batch. Defaults to 5 seconds.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Starting batch {batch_number} with {len(app_ids)} apps.\")\n",
    "    list_of_data = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(sgc.extract_data, app_id): app_id for app_id in app_ids}\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Processing Batch {batch_number}\"):\n",
    "            app_id = futures[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                if data:  # Add valid results to the list\n",
    "                    list_of_data.append(data)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing app ID {app_id}: {e}\")\n",
    "    \n",
    "    if list_of_data:\n",
    "        df = pd.DataFrame(list_of_data)\n",
    "        save_batch_to_csv(batch_number, df)\n",
    "        logging.info(f\"Completed processing batch {batch_number}\")\n",
    "    else:\n",
    "        logging.warning(f\"No data retrieved for batch {batch_number}\")\n",
    "\n",
    "    # Pause after each batch\n",
    "    logging.info(f\"Pausing for {batch_pause} seconds before the next batch.\")\n",
    "    time.sleep(batch_pause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "704856ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(dir_path):\n",
    "    \"\"\"Count the number of files in a given directory.\n",
    "\n",
    "    Parameters:\n",
    "        dir_path (str): Path to the directory.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of files in the directory.\n",
    "    \"\"\"\n",
    "    return sum(1 for path in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b5a30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV files\n",
    "files = ['newandtrending.csv', 'discounted.csv', 'comingsoon.csv', 'toprated.csv', 'topsellers.csv']\n",
    "\n",
    "# Dictionary to store the distinct lists for each file\n",
    "column_data = {}\n",
    "\n",
    "# Process each file\n",
    "for f in files:\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(f)\n",
    "        \n",
    "        # Extract the first column and remove duplicates\n",
    "        first_column = list(set(df.iloc[:, 0]))\n",
    "        \n",
    "        # Store the list in the dictionary with the filename as the key\n",
    "        column_data[f] = first_column\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {f}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(column_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "47d6f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = set()\n",
    "for col in df.columns:\n",
    "    unique_ids.update(df[col])\n",
    "\n",
    "unique_list = list(unique_ids)\n",
    "\n",
    "#print(\"Unique list of values:\", unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1cd1d032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'steam_games_scrapper' has no attribute 'extract_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m batch_number \u001b[38;5;241m=\u001b[39m batch_start \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[0;32m     11\u001b[0m ids \u001b[38;5;241m=\u001b[39m unique_list[batch_start:batch_start \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m---> 12\u001b[0m \u001b[43mprocess_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[75], line 14\u001b[0m, in \u001b[0;36mprocess_batch\u001b[1;34m(batch_number, app_ids, max_workers, batch_pause)\u001b[0m\n\u001b[0;32m     11\u001b[0m list_of_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m---> 14\u001b[0m     futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(sgc\u001b[38;5;241m.\u001b[39mextract_data, app_id): app_id \u001b[38;5;28;01mfor\u001b[39;00m app_id \u001b[38;5;129;01min\u001b[39;00m app_ids}\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(as_completed(futures), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(futures), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     17\u001b[0m         app_id \u001b[38;5;241m=\u001b[39m futures[future]\n",
      "Cell \u001b[1;32mIn[75], line 14\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m list_of_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m---> 14\u001b[0m     futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(\u001b[43msgc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_data\u001b[49m, app_id): app_id \u001b[38;5;28;01mfor\u001b[39;00m app_id \u001b[38;5;129;01min\u001b[39;00m app_ids}\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(as_completed(futures), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(futures), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     17\u001b[0m         app_id \u001b[38;5;241m=\u001b[39m futures[future]\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'steam_games_scrapper' has no attribute 'extract_data'"
     ]
    }
   ],
   "source": [
    "# Initialize the starting batch and batch size\n",
    "starting_batch = count_files('./indie_games')\n",
    "print()\n",
    "batch_size = 300\n",
    "a = starting_batch * batch_size\n",
    "b = len(unique_list)\n",
    "\n",
    "# Process each batch within the range of IDs\n",
    "for batch_start in range(a, b, batch_size):\n",
    "    batch_number = batch_start // batch_size\n",
    "    ids = unique_list[batch_start:batch_start + batch_size]\n",
    "    process_batch(batch_number, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba3568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
