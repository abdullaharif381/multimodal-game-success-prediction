{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:08:51.715849Z",
     "iopub.status.busy": "2024-10-27T10:08:51.715354Z",
     "iopub.status.idle": "2024-10-27T10:08:51.722878Z",
     "shell.execute_reply": "2024-10-27T10:08:51.721450Z",
     "shell.execute_reply.started": "2024-10-27T10:08:51.715802Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import webdriver_manager\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:10:09.885326Z",
     "iopub.status.busy": "2024-10-27T10:10:09.884847Z",
     "iopub.status.idle": "2024-10-27T10:10:09.893595Z",
     "shell.execute_reply": "2024-10-27T10:10:09.892211Z",
     "shell.execute_reply.started": "2024-10-27T10:10:09.885286Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_AppList(version):\n",
    "    url = f\"https://api.steampowered.com/ISteamApps/GetAppList/{version}/\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        apps = data['applist']['apps']\n",
    "        if version == 'v2':\n",
    "            return apps            \n",
    "        else:\n",
    "            return apps['app']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:15:15.555621Z",
     "iopub.status.busy": "2024-10-27T10:15:15.555076Z",
     "iopub.status.idle": "2024-10-27T10:15:17.812479Z",
     "shell.execute_reply": "2024-10-27T10:15:17.811325Z",
     "shell.execute_reply.started": "2024-10-27T10:15:15.555572Z"
    }
   },
   "outputs": [],
   "source": [
    "v1 = 'v1'\n",
    "v2 = 'v2'\n",
    "\n",
    "apps = get_AppList(v1)\n",
    "df1 = pd.DataFrame(apps)\n",
    "\n",
    "apps = get_AppList(v2)\n",
    "df2 = pd.DataFrame(apps)\n",
    "\n",
    "app_ids_df = pd.concat([df1, df2], ignore_index=True).drop_duplicates(subset='appid')  \n",
    "app_ids_df.to_csv('all_steam_games.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:15:24.867594Z",
     "iopub.status.busy": "2024-10-27T10:15:24.866673Z",
     "iopub.status.idle": "2024-10-27T10:15:24.880606Z",
     "shell.execute_reply": "2024-10-27T10:15:24.879170Z",
     "shell.execute_reply.started": "2024-10-27T10:15:24.867543Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>283650</th>\n",
       "      <td>70</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283651</th>\n",
       "      <td>8</td>\n",
       "      <td>winui2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283652</th>\n",
       "      <td>80</td>\n",
       "      <td>Counter-Strike: Condition Zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283653</th>\n",
       "      <td>90</td>\n",
       "      <td>Half-Life Dedicated Server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283654</th>\n",
       "      <td>92</td>\n",
       "      <td>Codename Gordon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        appid                            name\n",
       "283650     70                       Half-Life\n",
       "283651      8                          winui2\n",
       "283652     80  Counter-Strike: Condition Zero\n",
       "283653     90      Half-Life Dedicated Server\n",
       "283654     92                 Codename Gordon"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_ids_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:10:12.379187Z",
     "iopub.status.busy": "2024-10-27T10:10:12.378715Z",
     "iopub.status.idle": "2024-10-27T10:10:12.391042Z",
     "shell.execute_reply": "2024-10-27T10:10:12.389778Z",
     "shell.execute_reply.started": "2024-10-27T10:10:12.379140Z"
    }
   },
   "outputs": [],
   "source": [
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:10:12.393855Z",
     "iopub.status.busy": "2024-10-27T10:10:12.392849Z",
     "iopub.status.idle": "2024-10-27T10:10:12.407264Z",
     "shell.execute_reply": "2024-10-27T10:10:12.405853Z",
     "shell.execute_reply.started": "2024-10-27T10:10:12.393791Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:21:46.681523Z",
     "iopub.status.busy": "2024-10-27T10:21:46.680432Z",
     "iopub.status.idle": "2024-10-27T10:21:46.688127Z",
     "shell.execute_reply": "2024-10-27T10:21:46.686708Z",
     "shell.execute_reply.started": "2024-10-27T10:21:46.681459Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_AppData(url):\n",
    "    \"\"\"Fetch HTML content from a given URL.\n",
    "    \n",
    "    Parameters:\n",
    "        url (str): The URL of the webpage to fetch.\n",
    "\n",
    "    Returns:\n",
    "        BeautifulSoup object if successful, None otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Raise an HTTPError if status is 4xx or 5xx\n",
    "        return BeautifulSoup(response.text, 'lxml')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch data for URL {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:10:12.419338Z",
     "iopub.status.busy": "2024-10-27T10:10:12.418952Z",
     "iopub.status.idle": "2024-10-27T10:10:12.434578Z",
     "shell.execute_reply": "2024-10-27T10:10:12.433355Z",
     "shell.execute_reply.started": "2024-10-27T10:10:12.419299Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_general_details(soup):\n",
    "    \"\"\"Extract general details such as title, description, genre, and tags.\n",
    "\n",
    "    Parameters:\n",
    "        soup (BeautifulSoup): Parsed HTML content of the game page.\n",
    "\n",
    "    Returns:\n",
    "        tuple: title, description, content, genre, player type, tags list, and release date.\n",
    "    \"\"\"\n",
    "    title = description = content = genre = player = tags_list = release_date = None\n",
    "\n",
    "    try:\n",
    "        title = soup.find('div', class_='apphub_AppName').get_text(strip=True)\n",
    "        description = soup.find('div', class_='game_description_snippet').get_text(strip=True)\n",
    "        content_div = soup.find('div', class_='shared_game_rating')\n",
    "        content = content_div.find('p').get_text(strip=True) if content_div else None\n",
    "        genre = [g.get_text(strip=True) for g in soup.select('div.details_block a')]\n",
    "        tags_list = [tag.get_text(strip=True) for tag in soup.select('div.glance_tags a')]\n",
    "        release_date = soup.find('div', class_='date').get_text(strip=True).replace(',', '')\n",
    "        player = soup.find('a', class_='game_area_details_specs_ctn').find('div', class_='label').get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    return title, description, content, genre, player, tags_list, release_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:10:13.079158Z",
     "iopub.status.busy": "2024-10-27T10:10:13.078693Z",
     "iopub.status.idle": "2024-10-27T10:10:13.091336Z",
     "shell.execute_reply": "2024-10-27T10:10:13.090039Z",
     "shell.execute_reply.started": "2024-10-27T10:10:13.079114Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_details(div, index):\n",
    "    \"\"\"Extract developer or publisher details.\n",
    "    \n",
    "    Parameters:\n",
    "        div (list): List of div elements containing developer/publisher info.\n",
    "        index (int): Index of the div to extract details from.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (link, name) if found, else (None, None).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        detail_div = div[index].find('div', class_='summary column')\n",
    "        link = detail_div.find('a').get('href')\n",
    "        name = detail_div.get_text(strip=True)\n",
    "        return link, name\n",
    "    except (AttributeError, IndexError):\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_followers(link):\n",
    "    \"\"\"Fetch number of followers from a given developer/publisher link.\n",
    "    \n",
    "    Parameters:\n",
    "        link (str): URL of the developer/publisher page.\n",
    "    \n",
    "    Returns:\n",
    "        str: Number of followers or None if not found.\n",
    "    \"\"\"\n",
    "    soup = None\n",
    "    if not link:\n",
    "        return None\n",
    "    try:\n",
    "        soup = get_AppData(link)\n",
    "        res = soup.find('div', class_=\"num_followers\").get_text(strip=True).replace(',', '') if soup else None\n",
    "        return res\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_developer_publisher_details(soup):\n",
    "    \"\"\"Extract developer and publisher details, along with follower counts.\n",
    "    \n",
    "    Parameters:\n",
    "        soup (BeautifulSoup): Parsed HTML content of the game page.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Developer and publisher names, and their follower counts.\n",
    "    \"\"\"\n",
    "    developer = publisher = dev_followers = pub_followers = None\n",
    "    try:\n",
    "        divs = soup.find_all('div', class_='dev_row')\n",
    "        dev_link, developer = extract_details(divs, 0)\n",
    "        pub_link, publisher = extract_details(divs, 1)\n",
    "        dev_followers = fetch_followers(dev_link)\n",
    "        pub_followers = fetch_followers(pub_link)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return developer, publisher, dev_followers, pub_followers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:24:00.755074Z",
     "iopub.status.busy": "2024-10-27T10:24:00.754532Z",
     "iopub.status.idle": "2024-10-27T10:24:00.761519Z",
     "shell.execute_reply": "2024-10-27T10:24:00.760122Z",
     "shell.execute_reply.started": "2024-10-27T10:24:00.755028Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_price(soup):\n",
    "    \"\"\"Extract price and discount prices from the game page.\n",
    "    \n",
    "    Parameters:\n",
    "        soup (BeautifulSoup): Parsed HTML content of the game page.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Regular price and list of discount prices.\n",
    "    \"\"\"\n",
    "    price = discount_prices = None\n",
    "    try:\n",
    "        price = soup.find('div', class_='game_purchase_price').get_text(strip=True).replace('$', '')\n",
    "        discount_divs = soup.find_all('div', class_='discount_final_price')\n",
    "        discount_prices = [dp.get_text(strip=True).replace('$', '') for dp in discount_divs] or None\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    return price, discount_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:19:33.237270Z",
     "iopub.status.busy": "2024-10-27T10:19:33.236800Z",
     "iopub.status.idle": "2024-10-27T10:19:33.247941Z",
     "shell.execute_reply": "2024-10-27T10:19:33.246630Z",
     "shell.execute_reply.started": "2024-10-27T10:19:33.237224Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_review_count(soup):\n",
    "    \"\"\"Extract monthly and all-time review counts and ratings.\n",
    "    \n",
    "    Parameters:\n",
    "        soup (BeautifulSoup): Parsed HTML content of the game page.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Monthly and all-time review counts and ratings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        review_divs = soup.find_all('span', class_=\"nonresponsive_hidden responsive_reviewdesc\")\n",
    "        numbers = re.findall(r'\\d{1,3}(?:,\\d{3})*', review_divs[0].get_text())\n",
    "        positive_review_ratio_month, month_reviews = int(numbers[0].replace(',', '')), int(numbers[1].replace(',', ''))\n",
    "        numbers = re.findall(r'\\d{1,3}(?:,\\d{3})*', review_divs[1].get_text())\n",
    "        positive_review_ratio_all_time, total_reviews = int(numbers[0].replace(',', '')), int(numbers[1].replace(',', ''))\n",
    "    except (AttributeError, IndexError, ValueError):\n",
    "        return None, None, None, None\n",
    "    return month_reviews, positive_review_ratio_month, total_reviews, positive_review_ratio_all_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:19:34.056256Z",
     "iopub.status.busy": "2024-10-27T10:19:34.055816Z",
     "iopub.status.idle": "2024-10-27T10:19:34.066569Z",
     "shell.execute_reply": "2024-10-27T10:19:34.065369Z",
     "shell.execute_reply.started": "2024-10-27T10:19:34.056216Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_media_links(soup):\n",
    "    \"\"\"Extract media links, including header image, screenshots, and videos.\n",
    "    \n",
    "    Parameters:\n",
    "        soup (BeautifulSoup): Parsed HTML content of the game page.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Header URL, image URLs, thumbnail URLs, HD video URLs, and 480p video URLs.\n",
    "    \"\"\"\n",
    "    header_url = image_url_list = image_small_url_list = video_urls_hd_list = video_urls_480p_list = None\n",
    "    try:\n",
    "        header_url = soup.find('img', class_='game_header_image_full')['src']\n",
    "        image_url_list = [img['href'] for img in soup.find_all('a', class_='highlight_screenshot_link')]\n",
    "        image_small_url_list = [img.find('img')['src'] for img in soup.find_all('div', class_='highlight_strip_item highlight_strip_screenshot')]\n",
    "        video_links = soup.find_all('div', class_='highlight_player_item highlight_movie')\n",
    "        video_urls_hd_list = [v_link['data-mp4-hd-source'] for v_link in video_links if 'data-mp4-hd-source' in v_link.attrs]\n",
    "        video_urls_480p_list = [v_link['data-mp4-source'] for v_link in video_links if 'data-mp4-source' in v_link.attrs]\n",
    "    except (AttributeError, TypeError):\n",
    "        pass\n",
    "    return header_url, image_url_list, image_small_url_list, video_urls_hd_list, video_urls_480p_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:19:34.248939Z",
     "iopub.status.busy": "2024-10-27T10:19:34.248431Z",
     "iopub.status.idle": "2024-10-27T10:19:34.256684Z",
     "shell.execute_reply": "2024-10-27T10:19:34.255140Z",
     "shell.execute_reply.started": "2024-10-27T10:19:34.248891Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_requirements(soup):\n",
    "    \"\"\"Extract system requirements.\n",
    "    \n",
    "    Parameters:\n",
    "        soup (BeautifulSoup): Parsed HTML content of the game page.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of system requirements or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lines = soup.find('div', class_='sysreq_tabs').get_text(strip=True).split('\\n')\n",
    "        return [item.strip() for item in lines]\n",
    "    except AttributeError:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:19:34.593572Z",
     "iopub.status.busy": "2024-10-27T10:19:34.592253Z",
     "iopub.status.idle": "2024-10-27T10:19:34.599279Z",
     "shell.execute_reply": "2024-10-27T10:19:34.597869Z",
     "shell.execute_reply.started": "2024-10-27T10:19:34.593407Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_languages(soup):\n",
    "    \"\"\"Extract list of supported languages.\n",
    "    \n",
    "    Parameters:\n",
    "        soup (BeautifulSoup): Parsed HTML content of the game page.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of supported languages.\n",
    "    \"\"\"\n",
    "    return [td.get_text(strip=True) for td in soup.select(\"td.ellipsis\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T10:19:35.056269Z",
     "iopub.status.busy": "2024-10-27T10:19:35.055305Z",
     "iopub.status.idle": "2024-10-27T10:19:35.068392Z",
     "shell.execute_reply": "2024-10-27T10:19:35.067081Z",
     "shell.execute_reply.started": "2024-10-27T10:19:35.056216Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_data(appid):\n",
    "    \n",
    "    time.sleep(1) \n",
    "    url = f\"https://store.steampowered.com/app/{appid}/\"\n",
    "    soup = get_AppData(url) \n",
    "    \n",
    "    app_id = appid\n",
    "    title, description, content, genre, player, tags_list, release_date = find_general_details(soup)\n",
    "    developer, publisher, dev_followers, pub_followers = find_developer_publisher_details(soup) \n",
    "    price, discount_prices = find_price(soup)\n",
    "    month_reviews, pos_ratio_month, total_reviews, pos_ratio_all = find_review_count(soup)\n",
    "    header_url,image_url_list,image_small_url_list, video_urls_hd_list, video_urls_480p_list = find_media_links(soup)   \n",
    "    software = find_requirements(soup)\n",
    "    languages = find_languages(soup)\n",
    "        \n",
    "    data = {\n",
    "        'app_id': app_id,\n",
    "        'title': title,\n",
    "        'description': description,\n",
    "        'content': content,\n",
    "        'developer': developer,\n",
    "        'publisher': publisher,\n",
    "        'dev_followers':dev_followers,\n",
    "        'pub_followers' : pub_followers,\n",
    "        'genre': genre,\n",
    "        'release_date': release_date,\n",
    "        'price_usd': price,\n",
    "        'discount_price':discount_prices,\n",
    "        'software': software,\n",
    "        'player': player,\n",
    "        'languages' : languages,\n",
    "        'month_reviews': month_reviews,\n",
    "        'positive_ratio_month': pos_ratio_month,  \n",
    "        'total_reviews': total_reviews,\n",
    "        'positive_ratio_all': pos_ratio_all,\n",
    "        'tags_list': tags_list,\n",
    "        'header_url': header_url,\n",
    "        'image_url_list': image_url_list,\n",
    "        'image_small_url_list': image_small_url_list,\n",
    "        'video_urls_hd_list': video_urls_hd_list,\n",
    "        'video_urls_480p_list': video_urls_480p_list\n",
    "    }\n",
    "\n",
    "    \n",
    "    return data\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test_id = ['2878980', '10', '1293830', '306130']\n",
    "# for i in test_id:\n",
    "#     display(extract_data(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T09:48:29.418621Z",
     "iopub.status.busy": "2024-10-27T09:48:29.418165Z",
     "iopub.status.idle": "2024-10-27T10:04:05.008894Z",
     "shell.execute_reply": "2024-10-27T10:04:05.007139Z",
     "shell.execute_reply.started": "2024-10-27T09:48:29.418564Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def save_batch_to_csv(batch_number, df, directory='scraped_data_1'):\n",
    "    \"\"\"Save a DataFrame to a CSV file in a specified directory.\n",
    "\n",
    "    Parameters:\n",
    "        batch_number (int): Batch identifier for the file name.\n",
    "        df (pd.DataFrame): DataFrame containing batch data.\n",
    "        directory (str): Directory path where the CSV file will be saved. Defaults to 'scraped_data_1'.\n",
    "    \"\"\"\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    file_path = os.path.join(directory, f'steam_games_data_batch_{batch_number}.csv')\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Batch {batch_number} saved successfully to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_number, app_ids, max_workers=10):\n",
    "    \"\"\"Process a batch of app IDs and save the results to a CSV.\n",
    "\n",
    "    Parameters:\n",
    "        batch_number (int): Batch number for file naming.\n",
    "        app_ids (list): List of app IDs to process.\n",
    "        max_workers (int): Maximum number of threads for concurrent execution. Defaults to 10.\n",
    "    \"\"\"\n",
    "    list_of_data = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(extract_data, app_id) for app_id in app_ids]\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Processing Batch {batch_number}\"):\n",
    "            list_of_data.append(future.result())\n",
    "    df_scraped = pd.DataFrame(list_of_data)\n",
    "    save_batch_to_csv(batch_number, df_scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(dir_path):\n",
    "    \"\"\"Count the number of files in a given directory.\n",
    "\n",
    "    Parameters:\n",
    "        dir_path (str): Path to the directory.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of files in the directory.\n",
    "    \"\"\"\n",
    "    return sum(1 for path in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch 9:   2%|█▏                                                          | 20/1000 [00:55<14:01,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for URL https://store.steampowered.com/developer/ArcForged?snr=1_5_9__2000: HTTPSConnectionPool(host='store.steampowered.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch 9:   2%|█▍                                                          | 24/1000 [01:17<52:14,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for URL https://store.steampowered.com/app/1617948/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Read timed out. (read timeout=10)\n",
      "Failed to fetch data for URL https://store.steampowered.com/search/?publisher=Wankil%20Studio&snr=1_5_9__422: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /search/?publisher=Wankil%20Studio&snr=1_5_9__422 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CBE90E880>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for URL https://store.steampowered.com/app/1617949/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617949/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC378A490>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))Failed to fetch data for URL https://store.steampowered.com/search/?publisher=Wankil%20Studio&snr=1_5_9__422: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /search/?publisher=Wankil%20Studio&snr=1_5_9__422 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC3796A90>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "\n",
      "Failed to fetch data for URL https://store.steampowered.com/search/?publisher=Wankil%20Studio&snr=1_5_9__422: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /search/?publisher=Wankil%20Studio&snr=1_5_9__422 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CBFE5B640>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/search/?publisher=QuickBobber&snr=1_5_9__422: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /search/?publisher=QuickBobber&snr=1_5_9__422 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC3A57EB0>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/search/?publisher=Wankil%20Studio&snr=1_5_9__422: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /search/?publisher=Wankil%20Studio&snr=1_5_9__422 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC3D38F10>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/search/?publisher=Wankil%20Studio&snr=1_5_9__422: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /search/?publisher=Wankil%20Studio&snr=1_5_9__422 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC1A94AF0>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617950/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617950/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC19F1CD0>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617990/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617990/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC19F9640>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1618000/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1618000/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC19F97C0>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1618020/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1618020/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC1A03130>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1618030/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1618030/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC1A035E0>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617350/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617350/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC1A03F10>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617360/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617360/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC1A0D730>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617370/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617370/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC1A0DDC0>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617380/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617380/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC1A18730>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617390/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617390/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC1A200A0>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617420/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617420/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC1A20670>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617430/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617430/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC1A20FA0>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617450/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617450/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC1A27580>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617470/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617470/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000021CC1A27EB0>, 'Connection to store.steampowered.com timed out. (connect timeout=10)'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617480/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617480/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021CBE94A280>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617490/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617490/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021CBE94AB80>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617500/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617500/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021CBE9512E0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617501/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617501/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021CBE951A00>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617502/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617502/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021CBE95D160>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617503/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617503/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021CBE95DA60>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617510/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617510/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021CBE95DFA0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617520/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617520/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021CBE9678E0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617530/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617530/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021CBE967E20>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617540/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617540/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021CBE973760>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Failed to fetch data for URL https://store.steampowered.com/app/1617550/: HTTPSConnectionPool(host='store.steampowered.com', port=443): Max retries exceeded with url: /app/1617550/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021CBE94A280>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the starting batch and batch size\n",
    "starting_batch = count_files('./scraped_data_1')\n",
    "batch_size = 1000\n",
    "a = starting_batch * batch_size\n",
    "b = len(app_ids_df)\n",
    "\n",
    "# Process each batch within the range of IDs\n",
    "for batch_start in range(a, b, batch_size):\n",
    "    batch_number = batch_start // batch_size\n",
    "    ids = app_ids_df['appid'][batch_start:batch_start + batch_size].to_list()\n",
    "    process_batch(batch_number, ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://store.steampowered.com/charts/topselling/global\" \n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(url) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbody_element = driver.find_element(By.TAG_NAME, \"tbody\")\n",
    "tbody_html = tbody_element.get_attribute(\"outerHTML\")\n",
    "soup = BeautifulSoup(tbody_html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_ids = []\n",
    "ranks = []\n",
    "urls = []\n",
    "\n",
    "# Loop through each row in the <tbody> tag\n",
    "for row in soup.find_all('tr', class_=\"_2-RN6nWOY56sNmcDHu069P\"):\n",
    "    # Extract the rank\n",
    "    rank = row.find('td', class_=\"_34h48M_x9S-9Q2FFPX_CcU\").get_text(strip=True)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    # Extract the URL and app id\n",
    "    link = row.find('a', class_=\"_2C5PJOUH6RqyuBNEwaCE9X\")\n",
    "    if link:\n",
    "        url = link['href']\n",
    "        urls.append(url)\n",
    "        \n",
    "        # Extract app id from the URL using regex\n",
    "        app_id = re.search(r'/app/(\\d+)/', url)\n",
    "        app_ids.append(app_id.group(1) if app_id else None)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_top_100 = pd.DataFrame({\n",
    "    'appid': app_ids,\n",
    "    'rank': ranks,\n",
    "    'url': urls\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_top_100.to_csv(\"top_100_games.csv\", index=False)\n",
    "\n",
    "print(\"Data saved to top_100_games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_top_100.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-27T10:04:05.010128Z",
     "iopub.status.idle": "2024-10-27T10:04:05.010584Z",
     "shell.execute_reply": "2024-10-27T10:04:05.010367Z",
     "shell.execute_reply.started": "2024-10-27T10:04:05.010346Z"
    }
   },
   "outputs": [],
   "source": [
    "df_100 = pd.read_csv('top_100_games.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-27T10:04:05.012431Z",
     "iopub.status.idle": "2024-10-27T10:04:05.012914Z",
     "shell.execute_reply": "2024-10-27T10:04:05.012723Z",
     "shell.execute_reply.started": "2024-10-27T10:04:05.012697Z"
    }
   },
   "outputs": [],
   "source": [
    "df1_unique = app_ids_df.drop_duplicates(subset='appid')\n",
    "df2_unique = df_100.drop_duplicates(subset='appid')\n",
    "common_apps = pd.merge(df1_unique, df2_unique, on='appid', how='inner').sort_values(by='rank', ascending=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-27T10:04:05.014680Z",
     "iopub.status.idle": "2024-10-27T10:04:05.015084Z",
     "shell.execute_reply": "2024-10-27T10:04:05.014902Z",
     "shell.execute_reply.started": "2024-10-27T10:04:05.014881Z"
    }
   },
   "outputs": [],
   "source": [
    "common_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5956909,
     "sourceId": 9733603,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5957106,
     "sourceId": 9733864,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
