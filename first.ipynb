{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AppData(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return BeautifulSoup(response.text, 'lxml')\n",
    "    except Exception as e:\n",
    "        print(response.status_code)\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Valve'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://store.steampowered.com/app/10/CounterStrike/\"\n",
    "soup = get_AppData(url) \n",
    "dev_link = soup.find('div', class_ = \"details_block\").find_all('a')[1].get('href')\n",
    "developer = soup.find('div', class_ = \"details_block\").find_all('a')[1].text\n",
    "developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ids_names(file):\n",
    "    f = open(file, 'r')\n",
    "    json_string = f.read()\n",
    "    parsed_json = json.loads(json_string)\n",
    "    inner_json_string = parsed_json['applist']['apps']\n",
    "    ids = []\n",
    "    names = []\n",
    "    if file == 'v2.json':\n",
    "        for dic in inner_json_string:\n",
    "            ids.append(dic['appid'])\n",
    "            names.append(dic['name'])\n",
    "    else:\n",
    "        for dic in inner_json_string['app']:\n",
    "            ids.append(dic['appid'])\n",
    "            names.append(dic['name'])\n",
    "    return ids, names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ids, names = extract_ids_names('v1.json')\n",
    "ids2, names2 = extract_ids_names('v2.json')\n",
    "ids.extend(ids2)\n",
    "names.extend(names2)\n",
    "id_df = pd.DataFrame({'ID': ids, 'Title': names }, columns=['ID', 'Title'], index =  np.arange(1, len(ids)+1))\n",
    "id_df.head()\n",
    "id_df.to_csv('all_steam_games.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = pd.read_csv(\"all_steam_games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434807"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(i):\n",
    "        \n",
    "    try:\n",
    "        url = f\"https://store.steampowered.com/app/{i}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "    except Exception as e:\n",
    "        print(response.status_code)\n",
    "        print(e)\n",
    "        \n",
    "    app_id = i\n",
    "    title = soup.find('div', class_='apphub_AppName').text if soup.find('div', class_='apphub_AppName') else None\n",
    "    description = soup.find('div', class_='game_description_snippet').text.strip() if soup.find('div', class_='game_description_snippet') else None\n",
    "    try:\n",
    "        content_div = soup.find('div', class_='shared_game_rating') \n",
    "        content = content_div.find('p').text.strip()\n",
    "    except Exception as e:\n",
    "        content = None\n",
    "\n",
    "\n",
    "    try:\n",
    "        developer = soup.find('div', class_=\"summary column\", id = \"developers_list\").find('a').text.strip() if soup.find('div', class_=\"summary column\", id = \"developers_list\") else None\n",
    "        publisher = soup.find_all('div', class_='dev_row')[1].find('a').text.strip() if soup.find_all('div', class_='dev_row') else None\n",
    "    except Exception as e:\n",
    "        developer = None\n",
    "        publisher = None\n",
    "\n",
    "    \n",
    "    try:\n",
    "        genres = (soup.find('div', class_='details_block').find_all('a')) if soup.find('div', class_='details_block') else None\n",
    "        genre = [g.text for g in genres]  \n",
    "    except Exception as e: \n",
    "        genre = None    \n",
    "\n",
    "    try:\n",
    "        release_date = soup.find('div', class_='date').text.strip() \n",
    "    except Exception as e:\n",
    "        release_date = None\n",
    "    try:\n",
    "        price = soup.find('div', class_='game_purchase_price').text.strip() \n",
    "    except Exception as e:\n",
    "        price = None\n",
    "\n",
    "\n",
    "    try:\n",
    "        lines_platform = soup.find('div', class_='sysreq_tabs')\n",
    "        lines = lines_platform.text.strip(\"'\").strip().split('\\n')\n",
    "        software = [item.strip() for item in lines]\n",
    "    except Exception as e:\n",
    "        software = None\n",
    "        \n",
    "    try:\n",
    "        player = soup.find('a', class_='game_area_details_specs_ctn').find('div', class_='label').text.strip()\n",
    "    except Exception as e:\n",
    "        player = None\n",
    "\n",
    "    try:\n",
    "        month_reviews = soup.find('span', class_='nonresponsive_hidden responsive_reviewdesc').text.strip()\n",
    "        all_reviews = soup.find_all('span', class_='nonresponsive_hidden responsive_reviewdesc')[-1].text.strip()\n",
    "        positive_ratio = re.search(r'(\\d+)%', all_reviews).group(1) if 'positive' in all_reviews else None\n",
    "        total_reviews = re.search(r'(\\d{1,10}(?:,\\d{3})*) user reviews', all_reviews).group(1).replace(',', '') if all_reviews else None\n",
    "    except Exception as e:\n",
    "        month_reviews = None\n",
    "        positive_ratio = None\n",
    "        total_reviews = None\n",
    "\n",
    "    try:\n",
    "        tags_div = soup.find('div', class_='glance_tags popular_tags').find_all('a')\n",
    "        tags_all = [tag.text for tag in tags_div] if tags_div else None\n",
    "        tags_list = [item.strip() for item in tags_all]\n",
    "    except Exception as e:\n",
    "        tags_list = None\n",
    "\n",
    "\n",
    "    try:\n",
    "        header_url = soup.find('img', class_='game_header_image_full')['src']\n",
    "    except:\n",
    "        header_url = None\n",
    "    try:\n",
    "        image_link = soup.find_all('a', class_='highlight_screenshot_link') \n",
    "        image_url_list = [img['href'] for img in image_link] if image_link else None\n",
    "    except:\n",
    "        image_url_list = None\n",
    "        \n",
    "    try:\n",
    "        image_link_bar = soup.find_all('div', class_='highlight_strip_item highlight_strip_screenshot')\n",
    "        image_small_url_list = [img.find('img')['src'] for img in image_link_bar] if image_link_bar else None\n",
    "    except:\n",
    "        image_small_url_list= None\n",
    "        \n",
    "\n",
    "    video_link = soup.find_all('div', class_='highlight_player_item highlight_movie')\n",
    "    video_urls_hd_list = [v_link['data-mp4-hd-source'] for v_link in video_link] if video_link else None\n",
    "    video_urls_480p_list = [v_link['data-mp4-source'] for v_link in video_link] if video_link else None\n",
    "\n",
    "    # convert the data into a dictionary\n",
    "    data = {\n",
    "        'app_id': app_id,\n",
    "        'title': title,\n",
    "        'description': description,\n",
    "        'content': content,\n",
    "        'developer': developer,\n",
    "        'publisher': publisher,\n",
    "        'genre': genre,\n",
    "        'release_date': release_date,\n",
    "        'price': price,\n",
    "        'software': software,\n",
    "        'player': player,\n",
    "        'month_reviews': month_reviews,\n",
    "        'positive_ratio': positive_ratio,\n",
    "        'total_reviews': total_reviews,\n",
    "        'tags_list': tags_list,\n",
    "        'header_url': header_url,\n",
    "        'image_url_list': image_url_list,\n",
    "        'image_small_url_list': image_small_url_list,\n",
    "        'video_urls_hd_list': video_urls_hd_list,\n",
    "        'video_urls_480p_list': video_urls_480p_list\n",
    "    }\n",
    "    return data\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Data:   0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Data:   0%|          | 11/5000 [00:26<3:10:49,  2.30s/it]"
     ]
    }
   ],
   "source": [
    "list_of_data = []\n",
    "a = 5001\n",
    "b = 5003\n",
    "\n",
    "ids = id_df['ID'][a:b].to_list()\n",
    "\n",
    "for i in tqdm(ids, desc=\"Extracting Data\"):\n",
    "    list_of_data.append(extract_data(i))\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(list_of_data)\n",
    "\n",
    "df.to_csv('steam_games_data_2.csv', index=False)\n",
    "\n",
    "print(\"Data saved successfully to file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
